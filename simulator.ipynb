{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_metrics import evaluate_representativeness,evaluate_simplicity, evaluate_diversity,evaluate_incentive_compatibility,evaluate_resistance_to_malicious_behavior,evaluate_resistance_to_collusion,evaluate_robustness\n",
    "\n",
    "from voting_model import Simulation\n",
    "from voting_model import Voter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_method': 'median', 'vote_quorum': 17, 'min_amount': 1500, 'num_projects_above_quorum': 345, 'avg_payout': np.float64(86956.52168115941), 'median_payout': np.float64(54792.64), 'max_payout': np.float64(485438.44)}\n"
     ]
    }
   ],
   "source": [
    "simulation = Simulation()\n",
    "simulation.initialize_round(30_000_000)\n",
    "simulation.randomize_voters(150, willingness_to_spend=1, laziness_factor=0.6, expertise_factor=0.7)\n",
    "simulation.randomize_projects(600, coi_factor=0)\n",
    "simulation.simulate_voting()    \n",
    "results = simulation.allocate_votes('median', quorum=17, min_amount=1500)\n",
    "print(results)\n",
    "data = simulation.get_project_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voter Behaviours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idrees/Code/govxs/govxs_venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/idrees/Code/govxs/govxs_venv/lib/python3.9/site-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     results \u001b[38;5;241m=\u001b[39m simulation\u001b[38;5;241m.\u001b[39mallocate_votes(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m, quorum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m17\u001b[39m, min_amount\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1500\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(results)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mrun_simulation_with_voter_strategies\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m, in \u001b[0;36mrun_simulation_with_voter_strategies\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m simulation\u001b[38;5;241m.\u001b[39msimulate_voting()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Evaluate the results\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallocate_votes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmedian\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquorum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m17\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_amount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[0;32m~/Code/govxs/voting_model.py:291\u001b[0m, in \u001b[0;36mSimulation.allocate_votes\u001b[0;34m(self, scoring_method, quorum, min_amount, normalize)\u001b[0m\n\u001b[1;32m    282\u001b[0m allocations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mround\u001b[38;5;241m.\u001b[39mcalculate_allocations(scoring_method, quorum, min_amount, normalize)\n\u001b[1;32m    283\u001b[0m payouts \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m allocations \u001b[38;5;28;01mif\u001b[39;00m a \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscoring_method\u001b[39m\u001b[38;5;124m'\u001b[39m: scoring_method,\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvote_quorum\u001b[39m\u001b[38;5;124m'\u001b[39m: quorum,\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_amount\u001b[39m\u001b[38;5;124m'\u001b[39m: min_amount,\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_projects_above_quorum\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(payouts),\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_payout\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(payouts),\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_payout\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmedian(payouts),\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_payout\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayouts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m }\n",
      "File \u001b[0;32m~/Code/govxs/govxs_venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:2899\u001b[0m, in \u001b[0;36mmax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2781\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[1;32m   2782\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2783\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2784\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2785\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2786\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2787\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[1;32m   2898\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2900\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/govxs/govxs_venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "def run_simulation_with_voter_strategies():\n",
    "    simulation = Simulation()\n",
    "    simulation.initialize_round(30_000_000)\n",
    "    \n",
    "    # Example of setting up voters with different strategies\n",
    "    simulation.round.add_voters([\n",
    "        Voter(voter_id=i, op_available=1000, laziness=0.5, expertise=0.7) for i in range(50)\n",
    "    ])\n",
    "    simulation.round.add_voters([\n",
    "        Voter(voter_id=i, op_available=1000, laziness=0.5, expertise=0.7) for i in range(50, 100)\n",
    "    ])\n",
    "    simulation.round.add_voters([\n",
    "        Voter(voter_id=i, op_available=1000, laziness=0.5, expertise=0.7) for i in range(100, 150)\n",
    "    ])\n",
    "    \n",
    "    simulation.randomize_projects(600, coi_factor=0)\n",
    "    \n",
    "    simulation.simulate_voting()\n",
    "    \n",
    "    # Evaluate the results\n",
    "    results = simulation.allocate_votes('median', quorum=17, min_amount=1500)\n",
    "    print(results)\n",
    "\n",
    "run_simulation_with_voter_strategies()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_method': 'median', 'vote_quorum': 17, 'min_amount': 1500, 'num_projects_above_quorum': 355, 'avg_payout': np.float64(84507.0421971831), 'median_payout': np.float64(51909.21), 'max_payout': np.float64(445653.31)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>owner_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>num_votes</th>\n",
       "      <th>score</th>\n",
       "      <th>token_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.989416</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6.436696</td>\n",
       "      <td>104</td>\n",
       "      <td>984065.373305</td>\n",
       "      <td>442195.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.856216</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>4.514361</td>\n",
       "      <td>78</td>\n",
       "      <td>419604.457076</td>\n",
       "      <td>188551.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>3.761871</td>\n",
       "      <td>52</td>\n",
       "      <td>193483.362390</td>\n",
       "      <td>86942.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   project_id owner_id    rating  num_votes          score  token_amount\n",
       "0           0     None  1.989416          1       0.000000          0.00\n",
       "1           1     None  6.436696        104  984065.373305     442195.39\n",
       "2           2     None  1.856216          0       0.000000          0.00\n",
       "3           3     None  4.514361         78  419604.457076     188551.66\n",
       "4           4     None  3.761871         52  193483.362390      86942.85"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_voters=150\n",
    "num_projects=600\n",
    "max_allocation=30000000\n",
    "willingness_to_spend=1\n",
    "laziness_factor=0.6\n",
    "expertise_factor=0.7\n",
    "quorum=17\n",
    "min_amount=1500\n",
    "\n",
    "\n",
    "simulation = Simulation()\n",
    "\n",
    "simulation.initialize_round(max_allocation)\n",
    "simulation.randomize_voters(num_voters, willingness_to_spend, laziness_factor, expertise_factor)\n",
    "simulation.randomize_projects(num_projects, coi_factor=0)\n",
    "simulation.simulate_voting()    \n",
    "results = simulation.allocate_votes('median', quorum, min_amount)\n",
    "print(results)\n",
    "data = simulation.get_project_data()\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(data)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 1: Malicious behaviour Resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean - Resistance to Malicious Behavior Score: 30000000.006400004\n",
      "median - Resistance to Malicious Behavior Score: 29999999.996000003\n",
      "quadratic - Resistance to Malicious Behavior Score: 30000000.004299995\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from voting_model import Voter\n",
    "\n",
    "def evaluate_resistance_to_malicious_behavior(simulation, method, quorum, min_amount, num_tests=100):\n",
    "    results = []\n",
    "    for _ in range(num_tests):\n",
    "        baseline_allocations = run_baseline_simulation(simulation, method, quorum, min_amount)\n",
    "        malicious_allocations = introduce_malicious_voter(simulation, method, quorum, min_amount)\n",
    "        difference = measure_impact(baseline_allocations, malicious_allocations)\n",
    "        results.append(difference)\n",
    "    \n",
    "    avg_difference = np.mean(results)\n",
    "    return avg_difference\n",
    "\n",
    "# Helper functions\n",
    "def run_baseline_simulation(simulation, method, quorum, min_amount):\n",
    "    simulation.simulate_voting()\n",
    "    baseline_allocations = simulation.round.calculate_allocations(method, quorum, min_amount)\n",
    "    simulation.reset_round()\n",
    "    return baseline_allocations\n",
    "\n",
    "def introduce_malicious_voter(simulation, method, quorum, min_amount):\n",
    "    malicious_voter = Voter(voter_id=-1, op_available=simulation.round.max_funding, laziness=0, expertise=1)\n",
    "    malicious_voter.cast_vote(simulation.round.projects[0], malicious_voter.total_op)\n",
    "    simulation.round.voters.append(malicious_voter)\n",
    "    malicious_allocations = simulation.round.calculate_allocations(method, quorum, min_amount)\n",
    "    simulation.reset_round()\n",
    "    return malicious_allocations\n",
    "\n",
    "def measure_impact(baseline_allocations, malicious_allocations):\n",
    "    difference = np.abs(np.array(baseline_allocations) - np.array(malicious_allocations)).sum()\n",
    "    return difference\n",
    "\n",
    "# Example usage\n",
    "methods = ['mean', 'median', 'quadratic']\n",
    "simulation = Simulation()\n",
    "simulation.initialize_round(30_000_000)\n",
    "simulation.randomize_voters(150, willingness_to_spend=1, laziness_factor=0.6, expertise_factor=0.7)\n",
    "simulation.randomize_projects(600, coi_factor=0)\n",
    "\n",
    "for method in methods:\n",
    "    malicious_behavior_score = evaluate_resistance_to_malicious_behavior(simulation, method, quorum=17, min_amount=1500)\n",
    "    print(f'{method} - Resistance to Malicious Behavior Score: {malicious_behavior_score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bribery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean - Impact of Bribery Score: 29999999.9923\n",
      "median - Impact of Bribery Score: 30000000.0015\n",
      "quadratic - Impact of Bribery Score: 29999999.9915\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from voting_model import Voter\n",
    "\n",
    "def evaluate_impact_of_bribery(simulation, method, quorum, min_amount, bribe_amount, target_project_id, num_tests=100):\n",
    "    results = []\n",
    "    for _ in range(num_tests):\n",
    "        baseline_allocations = run_baseline_simulation(simulation, method, quorum, min_amount)\n",
    "        bribed_allocations = introduce_bribery(simulation, method, quorum, min_amount, bribe_amount, target_project_id)\n",
    "        difference = measure_impact(baseline_allocations, bribed_allocations)\n",
    "        results.append(difference)\n",
    "    \n",
    "    avg_difference = np.mean(results)\n",
    "    return avg_difference\n",
    "\n",
    "# Helper functions\n",
    "def run_baseline_simulation(simulation, method, quorum, min_amount):\n",
    "    simulation.simulate_voting()\n",
    "    baseline_allocations = simulation.round.calculate_allocations(method, quorum, min_amount)\n",
    "    simulation.reset_round()\n",
    "    return baseline_allocations\n",
    "\n",
    "def introduce_bribery(simulation, method, quorum, min_amount, bribe_amount, target_project_id):\n",
    "    # Select a voter to bribe\n",
    "    bribed_voter = np.random.choice(simulation.round.voters)\n",
    "    \n",
    "    # Ensure the voter has enough balance to cast the bribe amount\n",
    "    if bribed_voter.balance_op >= bribe_amount:\n",
    "        # Reset the voter's votes and balance\n",
    "        bribed_voter.reset_voter()\n",
    "        \n",
    "        # Cast a bribe vote for the target project\n",
    "        target_project = next(p for p in simulation.round.projects if p.project_id == target_project_id)\n",
    "        bribed_voter.cast_vote(target_project, bribe_amount)\n",
    "        \n",
    "        # Redistribute the remaining balance to other projects\n",
    "        remaining_balance = bribed_voter.balance_op\n",
    "        for project in simulation.round.projects:\n",
    "            if project.project_id != target_project_id:\n",
    "                amount = np.random.uniform(0, remaining_balance)\n",
    "                bribed_voter.cast_vote(project, amount)\n",
    "                remaining_balance -= amount\n",
    "    \n",
    "    bribed_allocations = simulation.round.calculate_allocations(method, quorum, min_amount)\n",
    "    simulation.reset_round()\n",
    "    return bribed_allocations\n",
    "\n",
    "def measure_impact(baseline_allocations, bribed_allocations):\n",
    "    difference = np.abs(np.array(baseline_allocations) - np.array(bribed_allocations)).sum()\n",
    "    return difference\n",
    "\n",
    "# Example usage\n",
    "methods = ['mean', 'median', 'quadratic']\n",
    "simulation = Simulation()\n",
    "simulation.initialize_round(30_000_000)\n",
    "simulation.randomize_voters(150, willingness_to_spend=1, laziness_factor=0.6, expertise_factor=0.7)\n",
    "simulation.randomize_projects(600, coi_factor=0)\n",
    "\n",
    "for method in methods:\n",
    "    target_project_id = np.random.choice([project.project_id for project in simulation.round.projects])\n",
    "    bribery_impact_score = evaluate_impact_of_bribery(simulation, method, quorum=17, min_amount=1500, bribe_amount=10000, target_project_id=target_project_id)\n",
    "    print(f'{method} - Impact of Bribery Score: {bribery_impact_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean - Impact of Bribery (Voter Perspective): 29999999.997599993\n",
      "mean - Impact of Bribery (Project Perspective): 29999999.997599993\n",
      "median - Impact of Bribery (Voter Perspective): 29999999.9929\n",
      "median - Impact of Bribery (Project Perspective): 29999999.9929\n",
      "quadratic - Impact of Bribery (Voter Perspective): 30000000.0072\n",
      "quadratic - Impact of Bribery (Project Perspective): 30000000.0072\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from voting_model import Voter\n",
    "\n",
    "def evaluate_impact_of_bribery(simulation, method, quorum, min_amount, bribe_amount, target_project_id, num_tests=100):\n",
    "    results_voter_perspective = []\n",
    "    results_project_perspective = []\n",
    "    for _ in range(num_tests):\n",
    "        baseline_allocations = run_baseline_simulation(simulation, method, quorum, min_amount)\n",
    "        \n",
    "        bribed_allocations_voter = introduce_bribery_voter_perspective(simulation, method, quorum, min_amount, bribe_amount, target_project_id)\n",
    "        difference_voter = measure_impact(baseline_allocations, bribed_allocations_voter)\n",
    "        results_voter_perspective.append(difference_voter)\n",
    "        \n",
    "        bribed_allocations_project = introduce_bribery_project_perspective(simulation, method, quorum, min_amount, bribe_amount, target_project_id)\n",
    "        difference_project = measure_impact(baseline_allocations, bribed_allocations_project)\n",
    "        results_project_perspective.append(difference_project)\n",
    "    \n",
    "    avg_difference_voter = np.mean(results_voter_perspective)\n",
    "    avg_difference_project = np.mean(results_project_perspective)\n",
    "    \n",
    "    return avg_difference_voter, avg_difference_project\n",
    "\n",
    "# Helper functions\n",
    "def run_baseline_simulation(simulation, method, quorum, min_amount):\n",
    "    simulation.simulate_voting()\n",
    "    baseline_allocations = simulation.round.calculate_allocations(method, quorum, min_amount)\n",
    "    simulation.reset_round()\n",
    "    return baseline_allocations\n",
    "\n",
    "def introduce_bribery_voter_perspective(simulation, method, quorum, min_amount, bribe_amount, target_project_id):\n",
    "    bribed_voter = np.random.choice(simulation.round.voters)\n",
    "    \n",
    "    if bribed_voter.balance_op >= bribe_amount:\n",
    "        bribed_voter.reset_voter()\n",
    "        target_project = next(p for p in simulation.round.projects if p.project_id == target_project_id)\n",
    "        bribed_voter.cast_vote(target_project, bribe_amount)\n",
    "        \n",
    "        remaining_balance = bribed_voter.balance_op\n",
    "        for project in simulation.round.projects:\n",
    "            if project.project_id != target_project_id:\n",
    "                amount = np.random.uniform(0, remaining_balance)\n",
    "                bribed_voter.cast_vote(project, amount)\n",
    "                remaining_balance -= amount\n",
    "    \n",
    "    bribed_allocations = simulation.round.calculate_allocations(method, quorum, min_amount)\n",
    "    simulation.reset_round()\n",
    "    return bribed_allocations\n",
    "\n",
    "def introduce_bribery_project_perspective(simulation, method, quorum, min_amount, bribe_amount, target_project_id):\n",
    "    project_owner_voter = np.random.choice(simulation.round.voters)\n",
    "    \n",
    "    if project_owner_voter.balance_op >= bribe_amount:\n",
    "        project_owner_voter.reset_voter()\n",
    "        target_project = next(p for p in simulation.round.projects if p.project_id == target_project_id)\n",
    "        project_owner_voter.cast_vote(target_project, bribe_amount)\n",
    "        \n",
    "        remaining_balance = project_owner_voter.balance_op\n",
    "        for project in simulation.round.projects:\n",
    "            if project.project_id != target_project_id:\n",
    "                amount = np.random.uniform(0, remaining_balance)\n",
    "                project_owner_voter.cast_vote(project, amount)\n",
    "                remaining_balance -= amount\n",
    "    \n",
    "    bribed_allocations = simulation.round.calculate_allocations(method, quorum, min_amount)\n",
    "    simulation.reset_round()\n",
    "    return bribed_allocations\n",
    "\n",
    "def measure_impact(baseline_allocations, bribed_allocations):\n",
    "    difference = np.abs(np.array(baseline_allocations) - np.array(bribed_allocations)).sum()\n",
    "    return difference\n",
    "\n",
    "# Example usage\n",
    "methods = ['mean', 'median', 'quadratic']\n",
    "simulation = Simulation()\n",
    "simulation.initialize_round(30_000_000)\n",
    "simulation.randomize_voters(150, willingness_to_spend=1, laziness_factor=0.6, expertise_factor=0.7)\n",
    "simulation.randomize_projects(600, coi_factor=0)\n",
    "\n",
    "for method in methods:\n",
    "    target_project_id = np.random.choice([project.project_id for project in simulation.round.projects])\n",
    "    avg_difference_voter, avg_difference_project = evaluate_impact_of_bribery(\n",
    "        simulation, method, quorum=17, min_amount=1500, bribe_amount=10000, target_project_id=target_project_id\n",
    "    )\n",
    "    print(f'{method} - Impact of Bribery (Voter Perspective): {avg_difference_voter}')\n",
    "    print(f'{method} - Impact of Bribery (Project Perspective): {avg_difference_project}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resistance to collusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_impact_of_collusion(simulation, method, quorum, min_amount, collusion_group_size, target_project_ids, num_tests=100):\n",
    "    results = []\n",
    "    for _ in range(num_tests):\n",
    "        baseline_allocations = run_baseline_simulation(simulation, method, quorum, min_amount)\n",
    "        colluded_allocations = introduce_collusion(simulation, method, quorum, min_amount, collusion_group_size, target_project_ids)\n",
    "        difference = measure_impact(baseline_allocations, colluded_allocations)\n",
    "        results.append(difference)\n",
    "    \n",
    "    avg_difference = np.mean(results)\n",
    "    return avg_difference\n",
    "\n",
    "# Helper functions\n",
    "def run_baseline_simulation(simulation, method, quorum, min_amount):\n",
    "    simulation.simulate_voting()\n",
    "    baseline_allocations = simulation.round.calculate_allocations(method, quorum, min_amount)\n",
    "    simulation.reset_round()\n",
    "    return baseline_allocations\n",
    "\n",
    "def introduce_collusion(simulation, method, quorum, min_amount, collusion_group_size, target_project_ids):\n",
    "    colluding_voters = np.random.choice(simulation.round.voters, size=collusion_group_size, replace=False)\n",
    "    \n",
    "    for voter in colluding_voters:\n",
    "        voter.reset_voter()\n",
    "        for project_id in target_project_ids:\n",
    "            target_project = next(p for p in simulation.round.projects if p.project_id == project_id)\n",
    "            amount = np.random.uniform(0, voter.balance_op / len(target_project_ids))\n",
    "            voter.cast_vote(target_project, amount)\n",
    "    \n",
    "    colluded_allocations = simulation.round.calculate_allocations(method, quorum, min_amount)\n",
    "    simulation.reset_round()\n",
    "    return colluded_allocations\n",
    "\n",
    "def measure_impact(baseline_allocations, colluded_allocations):\n",
    "    difference = np.abs(np.array(baseline_allocations) - np.array(colluded_allocations)).sum()\n",
    "    return difference\n",
    "\n",
    "# Example usage\n",
    "methods = ['mean', 'median', 'quadratic']\n",
    "simulation = Simulation()\n",
    "simulation.initialize_round(30_000_000)\n",
    "simulation.randomize_voters(150, willingness_to_spend=1, laziness_factor=0.6, expertise_factor=0.7)\n",
    "simulation.randomize_projects(600, coi_factor=0)\n",
    "\n",
    "for method in methods:\n",
    "    target_project_ids = np.random.choice([project.project_id for project in simulation.round.projects], size=3, replace=False)\n",
    "    collusion_impact_score = evaluate_impact_of_collusion(\n",
    "        simulation, method, quorum=17, min_amount=1500, collusion_group_size=10, target_project_ids=target_project_ids\n",
    "    )\n",
    "    print(f'{method} - Impact of Collusion Score: {collusion_impact_score}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incentive Compatibility: Strategy Proofness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean - Strategyproof Ratio: 0.0\n",
      "median - Strategyproof Ratio: 0.0\n",
      "quadratic - Strategyproof Ratio: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def evaluate_strategyproofness(simulation, method, quorum, min_amount, strategy, num_tests=100):\n",
    "    results = []\n",
    "    for _ in range(num_tests):\n",
    "        baseline_allocations, baseline_utilities = run_baseline_simulation(simulation, method, quorum, min_amount)\n",
    "        strategic_allocations, strategic_utilities = introduce_strategic_voting(simulation, method, quorum, min_amount, strategy)\n",
    "        is_strategyproof = measure_strategyproofness(baseline_utilities, strategic_utilities)\n",
    "        results.append(is_strategyproof)\n",
    "    \n",
    "    strategyproof_ratio = np.mean(results)\n",
    "    return strategyproof_ratio\n",
    "\n",
    "# Helper functions\n",
    "def calculate_utility(voter, allocations):\n",
    "    utility = 0\n",
    "    for vote in voter.votes:\n",
    "        project_id = vote.project.project_id\n",
    "        project_allocation = allocations[project_id] if project_id < len(allocations) else 0\n",
    "        utility += project_allocation * (vote.amount if vote.amount else 0)\n",
    "    return utility\n",
    "\n",
    "def run_baseline_simulation(simulation, method, quorum, min_amount):\n",
    "    simulation.simulate_voting()\n",
    "    baseline_allocations = simulation.round.calculate_allocations(method, quorum, min_amount)\n",
    "    voter_utilities = {\n",
    "        voter.voter_id: calculate_utility(voter, baseline_allocations)\n",
    "        for voter in simulation.round.voters\n",
    "    }\n",
    "    simulation.reset_round()\n",
    "    return baseline_allocations, voter_utilities\n",
    "\n",
    "def introduce_strategic_voting(simulation, method, quorum, min_amount, strategy):\n",
    "    strategic_voters = simulation.round.voters\n",
    "    \n",
    "    for voter in strategic_voters:\n",
    "        voter.reset_voter()\n",
    "        strategy(voter, simulation.round.projects)\n",
    "    \n",
    "    strategic_allocations = simulation.round.calculate_allocations(method, quorum, min_amount)\n",
    "    voter_utilities = {\n",
    "        voter.voter_id: calculate_utility(voter, strategic_allocations)\n",
    "        for voter in strategic_voters\n",
    "    }\n",
    "    simulation.reset_round()\n",
    "    return strategic_allocations, voter_utilities\n",
    "\n",
    "def measure_strategyproofness(baseline_utilities, strategic_utilities):\n",
    "    strategyproof = True\n",
    "    for voter_id in baseline_utilities:\n",
    "        if strategic_utilities[voter_id] > baseline_utilities[voter_id]:\n",
    "            strategyproof = False\n",
    "            break\n",
    "    return strategyproof\n",
    "\n",
    "# Example strategic voting strategy\n",
    "def strategic_voting_strategy(voter, projects):\n",
    "    # Example strategy: Vote only for the highest rated project\n",
    "    top_project = max(projects, key=lambda p: p.rating)\n",
    "    voter.cast_vote(top_project, voter.total_op)\n",
    "\n",
    "# Example usage\n",
    "methods = ['mean', 'median', 'quadratic']\n",
    "simulation = Simulation()\n",
    "simulation.initialize_round(30_000_000)\n",
    "simulation.randomize_voters(150, willingness_to_spend=1, laziness_factor=0.6, expertise_factor=0.7)\n",
    "simulation.randomize_projects(600, coi_factor=0)\n",
    "\n",
    "for method in methods:\n",
    "    strategyproof_ratio = evaluate_strategyproofness(\n",
    "        simulation, method, quorum=17, min_amount=1500, strategy=strategic_voting_strategy\n",
    "    )\n",
    "    print(f'{method} - Strategyproof Ratio: {strategyproof_ratio}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Strategy Proofness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean - Group Strategyproof Ratio: 1.0\n",
      "median - Group Strategyproof Ratio: 1.0\n",
      "quadratic - Group Strategyproof Ratio: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def evaluate_group_strategyproofness(simulation, method, quorum, min_amount, collusion_group_size, target_project_ids, num_tests=100):\n",
    "    results = []\n",
    "    for _ in range(num_tests):\n",
    "        baseline_allocations, baseline_utilities = run_baseline_simulation(simulation, method, quorum, min_amount)\n",
    "        colluded_allocations, colluded_utilities = introduce_group_collusion(simulation, method, quorum, min_amount, collusion_group_size, target_project_ids)\n",
    "        is_group_strategyproof = measure_group_strategyproofness(baseline_utilities, colluded_utilities)\n",
    "        results.append(is_group_strategyproof)\n",
    "    \n",
    "    group_strategyproof_ratio = np.mean(results)\n",
    "    return group_strategyproof_ratio\n",
    "\n",
    "# Helper functions\n",
    "def calculate_utility(voter, allocations):\n",
    "    utility = 0\n",
    "    for vote in voter.votes:\n",
    "        project_id = vote.project.project_id\n",
    "        project_allocation = allocations[project_id] if project_id < len(allocations) else 0\n",
    "        utility += project_allocation * (vote.amount if vote.amount else 0)\n",
    "    return utility\n",
    "\n",
    "def run_baseline_simulation(simulation, method, quorum, min_amount):\n",
    "    simulation.simulate_voting()\n",
    "    baseline_allocations = simulation.round.calculate_allocations(method, quorum, min_amount)\n",
    "    voter_utilities = {\n",
    "        voter.voter_id: calculate_utility(voter, baseline_allocations)\n",
    "        for voter in simulation.round.voters\n",
    "    }\n",
    "    simulation.reset_round()\n",
    "    return baseline_allocations, voter_utilities\n",
    "\n",
    "def introduce_group_collusion(simulation, method, quorum, min_amount, collusion_group_size, target_project_ids):\n",
    "    colluding_voters = np.random.choice(simulation.round.voters, size=collusion_group_size, replace=False)\n",
    "    \n",
    "    for voter in colluding_voters:\n",
    "        voter.reset_voter()\n",
    "        for project_id in target_project_ids:\n",
    "            target_project = next(p for p in simulation.round.projects if p.project_id == project_id)\n",
    "            amount = np.random.uniform(0, voter.balance_op / len(target_project_ids))\n",
    "            voter.cast_vote(target_project, amount)\n",
    "    \n",
    "    colluded_allocations = simulation.round.calculate_allocations(method, quorum, min_amount)\n",
    "    voter_utilities = {\n",
    "        voter.voter_id: calculate_utility(voter, colluded_allocations)\n",
    "        for voter in colluding_voters\n",
    "    }\n",
    "    simulation.reset_round()\n",
    "    return colluded_allocations, voter_utilities\n",
    "\n",
    "def measure_group_strategyproofness(baseline_utilities, colluded_utilities):\n",
    "    group_strategyproof = True\n",
    "    for voter_id in baseline_utilities:\n",
    "        if voter_id in colluded_utilities and colluded_utilities[voter_id] > baseline_utilities[voter_id]:\n",
    "            group_strategyproof = False\n",
    "            break\n",
    "    return group_strategyproof\n",
    "\n",
    "# Example usage\n",
    "methods = ['mean', 'median', 'quadratic']\n",
    "simulation = Simulation()\n",
    "simulation.initialize_round(30_000_000)\n",
    "simulation.randomize_voters(150, willingness_to_spend=1, laziness_factor=0.6, expertise_factor=0.7)\n",
    "simulation.randomize_projects(600, coi_factor=0)\n",
    "\n",
    "for method in methods:\n",
    "    target_project_ids = np.random.choice([project.project_id for project in simulation.round.projects], size=3, replace=False)\n",
    "    group_strategyproof_ratio = evaluate_group_strategyproofness(\n",
    "        simulation, method, quorum=17, min_amount=1500, collusion_group_size=10, target_project_ids=target_project_ids\n",
    "    )\n",
    "    print(f'{method} - Group Strategyproof Ratio: {group_strategyproof_ratio}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean - Robustness (Average Distance): 2232714.2490736637\n",
      "median - Robustness (Average Distance): 2399706.473329072\n",
      "quadratic - Robustness (Average Distance): 2172412.445962213\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_robustness(simulation, method, quorum, min_amount, num_changes=1, num_tests=100):\n",
    "    results = []\n",
    "    for _ in range(num_tests):\n",
    "        baseline_allocations = run_baseline_simulation(simulation, method, quorum, min_amount)\n",
    "        changed_allocations = introduce_random_changes(simulation, method, quorum, min_amount, num_changes)\n",
    "        distance = measure_distance(baseline_allocations, changed_allocations)\n",
    "        results.append(distance)\n",
    "    \n",
    "    avg_distance = np.mean(results)\n",
    "    return avg_distance\n",
    "\n",
    "# Helper functions\n",
    "def run_baseline_simulation(simulation, method, quorum, min_amount):\n",
    "    simulation.simulate_voting()\n",
    "    baseline_allocations = simulation.round.calculate_allocations(method, quorum, min_amount)\n",
    "    simulation.reset_round()\n",
    "    return baseline_allocations\n",
    "\n",
    "def introduce_random_changes(simulation, method, quorum, min_amount, num_changes=1):\n",
    "    changed_voter = np.random.choice(simulation.round.voters)\n",
    "    \n",
    "    for _ in range(num_changes):\n",
    "        project = np.random.choice(simulation.round.projects)\n",
    "        amount = np.random.uniform(0, changed_voter.balance_op)\n",
    "        changed_voter.cast_vote(project, amount)\n",
    "    \n",
    "    changed_allocations = simulation.round.calculate_allocations(method, quorum, min_amount)\n",
    "    simulation.reset_round()\n",
    "    return changed_allocations\n",
    "\n",
    "def measure_distance(baseline_allocations, changed_allocations):\n",
    "    distance = np.linalg.norm(np.array(baseline_allocations) - np.array(changed_allocations))\n",
    "    return distance\n",
    "\n",
    "# Example usage\n",
    "methods = ['mean', 'median', 'quadratic']\n",
    "simulation = Simulation()\n",
    "simulation.initialize_round(30_000_000)\n",
    "simulation.randomize_voters(150, willingness_to_spend=1, laziness_factor=0.6, expertise_factor=0.7)\n",
    "simulation.randomize_projects(600, coi_factor=0)\n",
    "\n",
    "for method in methods:\n",
    "    avg_distance = evaluate_robustness(\n",
    "        simulation, method, quorum=17, min_amount=1500, num_changes=1\n",
    "    )\n",
    "    print(f'{method} - Robustness (Average Distance): {avg_distance}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pareto efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(simulation, method, quorum, min_amount):\n",
    "    simulation.simulate_voting()\n",
    "    allocations = simulation.round.calculate_allocations(method, quorum, min_amount)\n",
    "    simulation.reset_round()\n",
    "    return allocations\n",
    "\n",
    "def check_pareto_efficiency(voters, allocations, projects):\n",
    "    pareto_violations = 0\n",
    "    for i in range(len(projects)):\n",
    "        for j in range(i + 1, len(projects)):\n",
    "            project_i = projects[i]\n",
    "            project_j = projects[j]\n",
    "            majority_prefers_i = sum(1 for voter in voters if voter.prefers(project_i, project_j)) > len(voters) / 2\n",
    "            majority_prefers_j = sum(1 for voter in voters if voter.prefers(project_j, project_i)) > len(voters) / 2\n",
    "            \n",
    "            if majority_prefers_i and allocations[project_i.project_id] < allocations[project_j.project_id]:\n",
    "                pareto_violations += 1\n",
    "            if majority_prefers_j and allocations[project_j.project_id] < allocations[project_i.project_id]:\n",
    "                pareto_violations += 1\n",
    "    return pareto_violations\n",
    "def evaluate_pareto_efficiency(simulation, method, quorum, min_amount, num_tests=100):\n",
    "    results = []\n",
    "    for _ in range(num_tests):\n",
    "        allocations = run_simulation(simulation, method, quorum, min_amount)\n",
    "        pareto_violations = check_pareto_efficiency(simulation.round.voters, allocations, simulation.round.projects)\n",
    "        results.append(pareto_violations)\n",
    "    \n",
    "    avg_pareto_violations = np.mean(results)\n",
    "    return avg_pareto_violations\n",
    "\n",
    "# Example usage\n",
    "methods = ['mean', 'median', 'quadratic']\n",
    "simulation = Simulation()\n",
    "simulation.initialize_round(30_000_000)\n",
    "simulation.randomize_voters(150, willingness_to_spend=1, laziness_factor=0.6, expertise_factor=0.7)\n",
    "simulation.randomize_projects(600, coi_factor=0)\n",
    "\n",
    "for method in methods:\n",
    "    avg_pareto_violations = evaluate_pareto_efficiency(\n",
    "        simulation, method, quorum=17, min_amount=1500\n",
    "    )\n",
    "    print(f'{method} - Average Pareto Violations: {avg_pareto_violations}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "govxs_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
